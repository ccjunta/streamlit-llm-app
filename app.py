import streamlit as st
import os

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# LLMã®åˆæœŸåŒ–
@st.cache_resource
def init_llm():
    # Streamlit Secretsã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
    try:
        openai_api_key = st.secrets["OPENAI_API_KEY"]
        return ChatOpenAI(
            model_name="gpt-4o-mini", 
            temperature=0,
            api_key=openai_api_key
        )
    except KeyError:
        st.error("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.info("Streamlit Cloud ã® Secrets ã§ OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

# å°‚é–€å®¶ã®ç¨®é¡ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®šç¾©
EXPERTS = {
    "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶ã§ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«é–¢ã™ã‚‹è³ªå•ã«å¯¾ã—ã¦ã€å®Ÿç”¨çš„ã§è©³ç´°ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "æ–™ç†å°‚é–€å®¶": "ã‚ãªãŸã¯æ–™ç†ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚æ–™ç†ã®ãƒ¬ã‚·ãƒ”ã€èª¿ç†æŠ€è¡“ã€é£Ÿæã®é¸ã³æ–¹ã«ã¤ã„ã¦å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "å¥åº·ãƒ»ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å°‚é–€å®¶": "ã‚ãªãŸã¯å¥åº·ã¨ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚é‹å‹•ã€æ „é¤Šã€å¥åº·ç¶­æŒã«ã¤ã„ã¦ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "æ—…è¡Œå°‚é–€å®¶": "ã‚ãªãŸã¯æ—…è¡Œã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚æ—…è¡Œè¨ˆç”»ã€è¦³å…‰åœ°ã®æƒ…å ±ã€æ—…è¡Œã®ã‚³ãƒ„ã«ã¤ã„ã¦è©³ã—ã„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
}

def get_expert_response(input_text: str, selected_expert: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«åŸºã¥ã„ã¦LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        input_text (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        selected_expert (str): é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®ç¨®é¡
    
    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”
    """
    llm = init_llm()
    
    # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨­å®š
    system_message = EXPERTS.get(selected_expert, EXPERTS["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶"])
    
    messages = [
        SystemMessage(content=system_message),
        HumanMessage(content=input_text)
    ]
    
    try:
        response = llm.invoke(messages)
        return response.content
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
def main():
    st.set_page_config(
        page_title="AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
    st.title("ğŸ¤– AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    # ã‚¢ãƒ—ãƒªã®æ¦‚è¦
    st.markdown("""
    ## ğŸ“‹ ã‚¢ãƒ—ãƒªã®æ¦‚è¦
    ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ç•°ãªã‚‹åˆ†é‡ã®å°‚é–€å®¶AIã¨ç›¸è«‡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
    è³ªå•ã—ãŸã„åˆ†é‡ã®å°‚é–€å®¶ã‚’é¸æŠã—ã¦ã€è‡ªç”±ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚
    
    ## ğŸ”§ æ“ä½œæ–¹æ³•
    1. **å°‚é–€å®¶ã‚’é¸æŠ**: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰ç›¸è«‡ã—ãŸã„åˆ†é‡ã®å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„
    2. **è³ªå•ã‚’å…¥åŠ›**: ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„  
    3. **å›ç­”ã‚’å–å¾—**: ã€Œå›ç­”ã‚’å–å¾—ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶AIãŒå›ç­”ã—ã¾ã™
    """)
    
    st.markdown("---")
    
    # ãƒ¡ã‚¤ãƒ³ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ğŸ¯ å°‚é–€å®¶ã‚’é¸æŠ")
        selected_expert = st.radio(
            "ç›¸è«‡ã—ãŸã„åˆ†é‡ã®å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„:",
            list(EXPERTS.keys()),
            index=0
        )
        
        # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®èª¬æ˜ã‚’è¡¨ç¤º
        st.info(f"**{selected_expert}**\n\n{EXPERTS[selected_expert]}")
    
    with col2:
        st.subheader("ğŸ’¬ è³ªå•ãƒ»ç›¸è«‡å†…å®¹")
        input_text = st.text_area(
            "è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
            height=150,
            placeholder="ä¾‹: Pythonã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"
        )
        
        # å›ç­”å–å¾—ãƒœã‚¿ãƒ³
        if st.button("ğŸš€ å›ç­”ã‚’å–å¾—", type="primary"):
            if input_text.strip():
                with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    response = get_expert_response(input_text, selected_expert)
                
                st.markdown("---")
                st.subheader("ğŸ“ å›ç­”")
                st.markdown(response)
            else:
                st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
